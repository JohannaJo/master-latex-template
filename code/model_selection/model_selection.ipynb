{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection for knowledge graph embeddings\n",
    "\n",
    "For hyperparameter optimisation random search is more optimal than grid search as the search space grows: *James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of Machine Learning Research, 13(Feb):281–305, 2012.*\n",
    "\n",
    "While this approach is not optimal, it is a strong baseline agains other more advanced methods such as Baysian optimisation: *Lisha Li and Kevin Jamieson. Hyperband: a novel bandit-based approach to hyperparameter optimization. Journal of Machine Learning Research, 18:1–52, 2018.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "np.random.seed(0)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot  as plt\n",
    "from candidate_generation import get_entities\n",
    "\n",
    "from ampligraph.evaluation import train_test_split_no_unseen \n",
    "from ampligraph.latent_features import RandomBaseline, TransE, DistMult, ComplEx#, HolE, ConvE, ConvKB\n",
    "from ampligraph.latent_features import save_model\n",
    "from ampligraph.evaluation import select_best_model_ranking # , mr_score, mrr_score, hits_at_n_score, evaluate_performance\n",
    "from ampligraph.latent_features import save_model#, restore_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258235, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(\"family_subset.txt\", dtype = 'object')\n",
    "entities_subset = get_entities(data, max_entities=1000, selection_method='random')\n",
    "#entities_subset = np.loadtxt(\"entities_subset_10000.txt\", dtype = 'object')\n",
    "printdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_test = train_test_split_no_unseen(data, test_size=0.2, seed=0)\n",
    "X_val, X_test = train_test_split_no_unseen(data, test_size=0.05, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "#X_train = data[:1000]\n",
    "#X_val = data[1000:1500]\n",
    "#X_test = data[1500:1900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206588, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245324, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12911, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Baseline\n",
    "Random baseline requires no hyperparameter search as it assigns a pseudo-random score to triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - All triples will be processed in the same batch (batches_count=1). When processing large graphs it is recommended to batch the input knowledge graph instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Home/siv30/fak006/miniconda/envs/ampligraph/lib/python3.7/site-packages/ampligraph/latent_features/models/EmbeddingModel.py:1329: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if corruption_entities == 'all':\n"
     ]
    }
   ],
   "source": [
    "model_class = RandomBaseline\n",
    "param_grid = {\n",
    "    \"seed\": 0\n",
    "}\n",
    "best_model, _, _, _, randomBaseline_mrr_test, _ = select_best_model_ranking(model_class, X_train, X_val, X_test,\n",
    "                          param_grid,\n",
    "                          max_combinations=1,\n",
    "                          use_filter=True,\n",
    "                          verbose=False,\n",
    "                          early_stopping=False, entities_subset=entities_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics[\"RandomBaseline\"] = randomBaseline_mrr_test\n",
    "save_model(best_model, './trained_models/RandomBaseline.pkl')\n",
    "del best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = TransE\n",
    "param_grid = {\n",
    "    \"batches_count\": [50],\n",
    "    \"seed\": 0,\n",
    "     \"epochs\": [10, 50, 100],\n",
    "     \"k\": [100, 200],\n",
    "     \"eta\": [5, 10, 15],\n",
    "     \"loss\": [\"pairwise\", \"nll\"],\n",
    "     \"loss_params\": {\n",
    "         \"margin\": [2]\n",
    "     },\n",
    "     \"embedding_model_params\": {\n",
    "     },\n",
    "     \"regularizer\": [\"LP\", None],\n",
    "     \"regularizer_params\": {\n",
    "         \"p\": [1, 3],\n",
    "         \"lambda\": [1e-4, 1e-5]\n",
    "     },\n",
    "     \"optimizer\": [\"adagrad\", \"adam\"],\n",
    "     \"optimizer_params\": {\n",
    "         \"lr\": lambda: np.random.uniform(0.0001, 0.01)\n",
    "     },\n",
    "     \"verbose\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Home/siv30/fak006/miniconda/envs/ampligraph/lib/python3.7/site-packages/ampligraph/latent_features/models/EmbeddingModel.py:1329: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if corruption_entities == 'all':\n",
      "/Home/siv30/fak006/miniconda/envs/ampligraph/lib/python3.7/site-packages/ampligraph/latent_features/models/EmbeddingModel.py:1329: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if corruption_entities == 'all':\n"
     ]
    }
   ],
   "source": [
    "best_model, _, _, _, transE_mrr_test, _ = select_best_model_ranking(model_class, X_train, X_val, X_test,\n",
    "                          param_grid,\n",
    "                          max_combinations=10,\n",
    "                          use_filter=True,\n",
    "                          verbose=False,\n",
    "                          early_stopping=False, entities_subset=entities_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model, './trained_models/TransE.pkl')\n",
    "test_metrics[\"TransE\"] = transE_mrr_test\n",
    "del best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test metrics to file\n",
    "file = open(\"test_metrics_random_transE.pkl\",\"wb\")\n",
    "\n",
    "# write the python object (dict) to pickle file\n",
    "pickle.dump(test_metrics,file)\n",
    "\n",
    "# close file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distmult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = DistMult\n",
    "param_grid = {\n",
    "    \"batches_count\": [50],\n",
    "    \"seed\": 0,\n",
    "    \"epochs\": [10, 50, 100],\n",
    "    \"k\": [100, 200],\n",
    "    \"eta\": [5, 10, 15],\n",
    "    \"loss\": [\"pairwise\", \"nll\"],\n",
    "    \"loss_params\": {\n",
    "        \"margin\": [2]\n",
    "    },\n",
    "    \"embedding_model_params\": {\n",
    "        \n",
    "    },\n",
    "    \"regularizer\": [\"LP\", None],\n",
    "    \"regularizer_params\": {\n",
    "        \"p\": [1, 3],\n",
    "        \"lambda\": [1e-4, 1e-5]\n",
    "    },\n",
    "    \"optimizer\": [\"adagrad\", \"adam\"],\n",
    "    \"optimizer_params\": {\n",
    "        \"lr\": lambda: np.random.uniform(0.0001, 0.01)\n",
    "    },\n",
    "    \"verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, _, _, _, distMult_mrr_test, _ = select_best_model_ranking(model_class, X_train, X_val, X_test,\n",
    "                          param_grid,\n",
    "                          max_combinations=10,\n",
    "                          use_filter=True,\n",
    "                          verbose=False,\n",
    "                          early_stopping=False, entities_subset=entities_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model, './trained_models/DistMult.pkl')\n",
    "test_metrics[\"DistMult\"] = distMult_mrr_test\n",
    "del best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ComplEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = ComplEx\n",
    "param_grid = {\n",
    "    \"batches_count\": [50],\n",
    "    \"seed\": 0,\n",
    "    \"epochs\": [10, 50, 100],\n",
    "    \"k\": [100, 200],\n",
    "    \"eta\": [5, 10, 15],\n",
    "    \"loss\": [\"pairwise\", \"nll\"],\n",
    "    \"loss_params\": {\n",
    "        \"margin\": [2]\n",
    "    },\n",
    "    \"embedding_model_params\": {\n",
    "        \n",
    "    },\n",
    "    \"regularizer\": [\"LP\", None],\n",
    "    \"regularizer_params\": {\n",
    "        \"p\": [1, 3],\n",
    "        \"lambda\": [1e-4, 1e-5]\n",
    "    },\n",
    "    \"optimizer\": [\"adagrad\", \"adam\"],\n",
    "    \"optimizer_params\": {\n",
    "        \"lr\": lambda: np.random.uniform(0.0001, 0.01)\n",
    "    },\n",
    "    \"verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test metrics to file\n",
    "file = open(\"test_metrics_random_transE_distMult.pkl\",\"wb\")\n",
    "\n",
    "# write the python object (dict) to pickle file\n",
    "pickle.dump(test_metrics,file)\n",
    "\n",
    "# close file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_metrics_random_transE_distMult.pkl', 'rb') as f:\n",
    "    test_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, _, _, _, complEx_mrr_test, _ = select_best_model_ranking(model_class, X_train, X_val, X_test,\n",
    "                          param_grid,\n",
    "                          max_combinations=10,\n",
    "                          use_filter=True,\n",
    "                          verbose=False,\n",
    "                          early_stopping=False, entities_subset=entities_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model, './trained_models/ComplEx.pkl')\n",
    "test_metrics[\"ComplEx\"] = complEx_mrr_test\n",
    "#del best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test metrics to file\n",
    "file = open(\"test_metrics.pkl\",\"wb\")\n",
    "\n",
    "# write the python object (dict) to pickle file\n",
    "pickle.dump(test_metrics,file)\n",
    "\n",
    "# close file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "names = [\"RandomBaseline\", \"TransE\", \"DistMult\", \"ComplEx\"]\n",
    "values = [list(test_metrics[\"RandomBaseline\"].values())[0], \n",
    "          list(test_metrics[\"TransE\"].values())[0], \n",
    "          list(test_metrics[\"DistMult\"].values())[0], \n",
    "          list(test_metrics[\"ComplEx\"].values())[0]]\n",
    "plt.bar(names, values, color=['red', 'green', 'blue', 'orange'])\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Model class')\n",
    "plt.title(\"MRR score on test data\")\n",
    "plt.savefig(\"mrr_scores.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "names = [\"RandomBaseline\", \"TransE\", \"DistMult\", \"ComplEx\"]\n",
    "values = [list(test_metrics[\"RandomBaseline\"].values())[1], \n",
    "          list(test_metrics[\"TransE\"].values())[1], \n",
    "          list(test_metrics[\"DistMult\"].values())[1], \n",
    "          list(test_metrics[\"ComplEx\"].values())[1]]\n",
    "plt.bar(names, values, color=['red', 'green', 'blue', 'orange'])\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Model class')\n",
    "plt.title(\"MR score on test data\");\n",
    "plt.savefig(\"mr_scores.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Hits@1','Hits@3','Hits@10']\n",
    "metrics_RandomBaseline = list(test_metrics[\"RandomBaseline\"].values())[2:5]\n",
    "metrics_TransE = list(test_metrics[\"TransE\"].values())[2:5]\n",
    "metrics_DistMult = list(test_metrics[\"DistMult\"].values())[2:5]\n",
    "metrics_ComplEx = list(test_metrics[\"ComplEx\"].values())[2:5]\n",
    "\n",
    "\n",
    "x = (np.arange(len(labels)))*3  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "mpl.style.use(\"bmh\")\n",
    "fig, ax = plt.subplots()\n",
    "bar_C11 = ax.bar(x - 3*(width), metrics_RandomBaseline, width, label='RandomBaseline')\n",
    "bar_C12 = ax.bar(x - 2*(width), metrics_TransE, width, label='TransE')\n",
    "bar_C21 = ax.bar(x - width, metrics_DistMult, width, label='DistMult')\n",
    "bar_C22 = ax.bar(x, metrics_ComplEx, width, label='ComplEx')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Hit scores for models')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"hit_scores.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
