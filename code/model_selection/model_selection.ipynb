{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection for knowledge graph embeddings\n",
    "\n",
    "For hyperparameter optimisation random search is more optimal than grid search as the search space grows: *James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of Machine Learning Research, 13(Feb):281–305, 2012.*\n",
    "\n",
    "While this approach is not optimal, it is a strong baseline agains other more advanced methods such as Baysian optimisation: *Lisha Li and Kevin Jamieson. Hyperband: a novel bandit-based approach to hyperparameter optimization. Journal of Machine Learning Research, 18:1–52, 2018.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from ampligraph.evaluation import train_test_split_no_unseen \n",
    "from ampligraph.latent_features import RandomBaseline, TransE, DistMult, ComplEx, HolE, ConvE, ConvKB\n",
    "from ampligraph.latent_features import save_model\n",
    "from ampligraph.evaluation import evaluate_performance, select_best_model_ranking, mr_score, mrr_score, hits_at_n_score\n",
    "from ampligraph.latent_features import save_model, restore_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"family_subset_test.txt\", dtype = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"X_train.txt\", dtype = 'object')\n",
    "X_train = data[:1000]\n",
    "X_val = data[1000:1500]\n",
    "X_test = data[1600:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from https://github.com/Accenture/AmpliGraph/blob/master/ampligraph/evaluation/protocol.py\n",
    "def evaluation(ranks):\n",
    "        mrr = mrr_score(ranks)\n",
    "        mr = mr_score(ranks)\n",
    "        hits_1 = hits_at_n_score(ranks, n=1)\n",
    "        hits_3 = hits_at_n_score(ranks, n=3)\n",
    "        hits_10 = hits_at_n_score(ranks, n=10)\n",
    "        test_evaluation = {\n",
    "            \"mrr\": mrr,\n",
    "            \"mr\": mr,\n",
    "            \"hits_1\": hits_1,\n",
    "            \"hits_3\": hits_3,\n",
    "            \"hits_10\": hits_10\n",
    "        }\n",
    "        return test_evaluation\n",
    "    \n",
    "def get_metrics(model, test_data, complete_data):\n",
    "    ranks = evaluate_performance(complete_data, model=model,\n",
    "                                         filter_triples=complete_data, verbose=False,\n",
    "                                         entities_subset=None,\n",
    "                                         use_default_protocol=False,\n",
    "                                         corrupt_side='s,o')\n",
    "    return evaluation(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Baseline\n",
    "Random baseline requires no hyperparameter search as it assigns a pseudo-random score to triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Q1000505', 'spouse', 'Q540597']], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Q1000596', 'father', 'Q701504'],\n",
       "       ['Q1000596', 'sibling', 'Q718827']], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - All triples will be processed in the same batch (batches_count=1). When processing large graphs it is recommended to batch the input knowledge graph instead.\n"
     ]
    }
   ],
   "source": [
    "model = RandomBaseline()\n",
    "model.fit(np.concatenate((X_train, X_val)))\n",
    "test_metrics[\"RandomBaseline\"] = get_metrics(model, X_test, data)\n",
    "#save_model(model, './trained_models/RandomBaseline.pkl')\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distmult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ComplEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = ComplEx\n",
    "param_grid = {\n",
    "    \"batches_count\": [50],\n",
    "    \"seed\": 0,\n",
    "    \"epochs\": [10],\n",
    "    \"k\": [100, 200],\n",
    "    \"eta\": [5, 10, 15],\n",
    "    \"loss\": [\"pairwise\", \"nll\"],\n",
    "    \"loss_params\": {\n",
    "        \"margin\": [2]\n",
    "    },\n",
    "    \"embedding_model_params\": {\n",
    "        \n",
    "    },\n",
    "    \"regularizer\": [\"LP\", None],\n",
    "    \"regularizer_params\": {\n",
    "        \"p\": [1, 3],\n",
    "        \"lambda\": [1e-4, 1e-5]\n",
    "    },\n",
    "    \"optimizer\": [\"adagrad\", \"adam\"],\n",
    "    \"optimizer_params\": {\n",
    "        \"lr\": lambda: np.random.uniform(0.0001, 0.01)\n",
    "    },\n",
    "    \"verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average ComplEx Loss:   0.001314: 100%|█████| 10/10 [00:02<00:00,  3.40epoch/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 36.20it/s]\n",
      "Average ComplEx Loss:   1.990262: 100%|█████| 10/10 [00:02<00:00,  4.39epoch/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 16.03it/s]\n",
      "Average ComplEx Loss:   0.060085: 100%|█████| 10/10 [00:06<00:00,  1.59epoch/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 22.32it/s]\n",
      "Average ComplEx Loss:   0.117074: 100%|█████| 10/10 [00:09<00:00,  1.07epoch/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 23.79it/s]\n",
      "Average ComplEx Loss:   0.000000: 100%|█████| 10/10 [00:05<00:00,  1.99epoch/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 25.00it/s]\n",
      "Average ComplEx Loss:   0.059909: 100%|█████| 10/10 [00:09<00:00,  1.11epoch/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 25.78it/s]\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 22.73it/s]\n"
     ]
    }
   ],
   "source": [
    "best_model, best_params, best_mrr_train, ranks_test, mrr_test, experimental_history = select_best_model_ranking(model_class, X_train, X_val, X_test,\n",
    "                          param_grid,\n",
    "                          max_combinations=6,\n",
    "                          use_filter=True,\n",
    "                          verbose=False,\n",
    "                          early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model, './trained_models/ComplEx.pkl')\n",
    "del best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 200,\n",
       " 'eta': 5,\n",
       " 'epochs': 10,\n",
       " 'batches_count': 50,\n",
       " 'seed': 0,\n",
       " 'embedding_model_params': {},\n",
       " 'optimizer': 'adam',\n",
       " 'optimizer_params': {'lr': 0.00957583607363516},\n",
       " 'loss': 'nll',\n",
       " 'loss_params': {},\n",
       " 'regularizer': 'LP',\n",
       " 'regularizer_params': {'p': 3, 'lambda': 0.0001},\n",
       " 'initializer': 'xavier',\n",
       " 'initializer_params': {'uniform': False},\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_hyperparameter_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batches_count': 50,\n",
       " 'seed': 0,\n",
       " 'epochs': 10,\n",
       " 'k': 200,\n",
       " 'eta': 5,\n",
       " 'loss': 'nll',\n",
       " 'loss_params': {},\n",
       " 'embedding_model_params': {},\n",
       " 'regularizer': 'LP',\n",
       " 'regularizer_params': {'p': 3, 'lambda': 0.0001},\n",
       " 'optimizer': 'adam',\n",
       " 'optimizer_params': {'lr': 0.00957583607363516},\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013912616006013234"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mrr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 541,  388],\n",
       "       [1076,  415],\n",
       "       [1296, 1364],\n",
       "       [1584, 1098]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mrr': 0.0013514447148697825,\n",
       " 'mr': 970.25,\n",
       " 'hits_1': 0.0,\n",
       " 'hits_3': 0.0,\n",
       " 'hits_10': 0.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_name': 'ComplEx',\n",
       "  'model_params': {'batches_count': 50,\n",
       "   'seed': 0,\n",
       "   'epochs': 10,\n",
       "   'k': 100,\n",
       "   'eta': 10,\n",
       "   'loss': 'pairwise',\n",
       "   'loss_params': {'margin': 2},\n",
       "   'embedding_model_params': {},\n",
       "   'regularizer': None,\n",
       "   'regularizer_params': {},\n",
       "   'optimizer': 'adam',\n",
       "   'optimizer_params': {'lr': 0.004294182513455157},\n",
       "   'verbose': True},\n",
       "  'results': {'mrr': 0.0025149009856549644,\n",
       "   'mr': 765.3,\n",
       "   'hits_1': 0.0,\n",
       "   'hits_3': 0.0,\n",
       "   'hits_10': 0.0}},\n",
       " {'model_name': 'ComplEx',\n",
       "  'model_params': {'batches_count': 50,\n",
       "   'seed': 0,\n",
       "   'epochs': 10,\n",
       "   'k': 200,\n",
       "   'eta': 15,\n",
       "   'loss': 'pairwise',\n",
       "   'loss_params': {'margin': 2},\n",
       "   'embedding_model_params': {},\n",
       "   'regularizer': None,\n",
       "   'regularizer_params': {},\n",
       "   'optimizer': 'adagrad',\n",
       "   'optimizer_params': {'lr': 0.0027992973163431206},\n",
       "   'verbose': True},\n",
       "  'results': {'mrr': 0.0015205850240877599,\n",
       "   'mr': 1110.0,\n",
       "   'hits_1': 0.0,\n",
       "   'hits_3': 0.0,\n",
       "   'hits_10': 0.0}},\n",
       " {'model_name': 'ComplEx',\n",
       "  'model_params': {'batches_count': 50,\n",
       "   'seed': 0,\n",
       "   'epochs': 10,\n",
       "   'k': 200,\n",
       "   'eta': 15,\n",
       "   'loss': 'nll',\n",
       "   'loss_params': {},\n",
       "   'embedding_model_params': {},\n",
       "   'regularizer': None,\n",
       "   'regularizer_params': {},\n",
       "   'optimizer': 'adam',\n",
       "   'optimizer_params': {'lr': 0.009263406719097344},\n",
       "   'verbose': True},\n",
       "  'results': {'mrr': 0.00789930997145158,\n",
       "   'mr': 532.5,\n",
       "   'hits_1': 0.0,\n",
       "   'hits_3': 0.0,\n",
       "   'hits_10': 0.0}},\n",
       " {'model_name': 'ComplEx',\n",
       "  'model_params': {'batches_count': 50,\n",
       "   'seed': 0,\n",
       "   'epochs': 10,\n",
       "   'k': 200,\n",
       "   'eta': 5,\n",
       "   'loss': 'nll',\n",
       "   'loss_params': {},\n",
       "   'embedding_model_params': {},\n",
       "   'regularizer': 'LP',\n",
       "   'regularizer_params': {'p': 3, 'lambda': 0.0001},\n",
       "   'optimizer': 'adam',\n",
       "   'optimizer_params': {'lr': 0.00957583607363516},\n",
       "   'verbose': True},\n",
       "  'results': {'mrr': 0.013912616006013234,\n",
       "   'mr': 232.8,\n",
       "   'hits_1': 0.0,\n",
       "   'hits_3': 0.0,\n",
       "   'hits_10': 0.0}},\n",
       " {'model_name': 'ComplEx',\n",
       "  'model_params': {'batches_count': 50,\n",
       "   'seed': 0,\n",
       "   'epochs': 10,\n",
       "   'k': 200,\n",
       "   'eta': 5,\n",
       "   'loss': 'pairwise',\n",
       "   'loss_params': {'margin': 2},\n",
       "   'embedding_model_params': {},\n",
       "   'regularizer': None,\n",
       "   'regularizer_params': {},\n",
       "   'optimizer': 'adam',\n",
       "   'optimizer_params': {'lr': 0.0052527270475569285},\n",
       "   'verbose': True},\n",
       "  'results': {'mrr': 0.0014835254428248628,\n",
       "   'mr': 1009.7,\n",
       "   'hits_1': 0.0,\n",
       "   'hits_3': 0.0,\n",
       "   'hits_10': 0.0}},\n",
       " {'model_name': 'ComplEx',\n",
       "  'model_params': {'batches_count': 50,\n",
       "   'seed': 0,\n",
       "   'epochs': 10,\n",
       "   'k': 200,\n",
       "   'eta': 15,\n",
       "   'loss': 'nll',\n",
       "   'loss_params': {},\n",
       "   'embedding_model_params': {},\n",
       "   'regularizer': 'LP',\n",
       "   'regularizer_params': {'p': 3, 'lambda': 1e-05},\n",
       "   'optimizer': 'adam',\n",
       "   'optimizer_params': {'lr': 0.00945222227879088},\n",
       "   'verbose': True},\n",
       "  'results': {'mrr': 0.006406954593266639,\n",
       "   'mr': 639.0,\n",
       "   'hits_1': 0.0,\n",
       "   'hits_3': 0.0,\n",
       "   'hits_10': 0.0}}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# KG embedding using Ampligraph\n",
    "\n",
    "**THIS SECTION CONTAINS CODE THAT WOULD HAVE BEEN USED IF NOT FOR ISSUES WITH THE APLIGRAPH LIBRARY**\n",
    "\n",
    "AmpliGraph has implemented [several Knoweldge Graph Embedding models](https://docs.ampligraph.org/en/latest/ampligraph.latent_features.html#knowledge-graph-embedding-models) (TransE, ComplEx, DistMult, HolE), but for this project we will only use the [ComplEx](https://docs.ampligraph.org/en/latest/generated/ampligraph.latent_features.ComplEx.html#ampligraph.latent_features.ComplEx) model (with  default values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = ComplEx(batches_count=100, \n",
    "                seed=0, \n",
    "                epochs=100, \n",
    "                k=150, \n",
    "                eta=5,\n",
    "                optimizer='adam', \n",
    "                optimizer_params={'lr':1e-3},\n",
    "                loss='multiclass_nll', \n",
    "                regularizer='LP', \n",
    "                regularizer_params={'p':3, 'lambda':1e-5}, \n",
    "                verbose=True)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "model.fit(X_train, early_stopping = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average ComplEx Loss:   0.000690: 100%|█| 100/100 [2:16:44<00:00, 82.05s/epoch]\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "model.fit(X_train, early_stopping = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, './Wikidata_family_subset_100_epocs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to save new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = restore_model('./Wikidata_family_subset_100_epocs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - DeprecationWarning: use_default_protocol will be removed in future. Please use corrupt_side argument instead.\n",
      "WARNING - You are attempting to use 116236 distinct entities to generate synthetic negatives in the evaluation\n",
      "    protocol. This may be unnecessary and will lead to a 'harder' task. Besides, it will lead to a much slower\n",
      "    evaluation procedure. We recommended to set the 'corruption_entities' argument to a reasonably sized set\n",
      "    of entities. The size of corruption_entities depends on your domain-specific task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\johan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ampligraph\\evaluation\\protocol.py:952: UserWarning: You are attempting to use 116236 distinct entities to generate synthetic negatives in the evaluation\n",
      "    protocol. This may be unnecessary and will lead to a 'harder' task. Besides, it will lead to a much slower\n",
      "    evaluation procedure. We recommended to set the 'corruption_entities' argument to a reasonably sized set\n",
      "    of entities. The size of corruption_entities depends on your domain-specific task.\n",
      "  warnings.warn(warn_msg % ent_for_corruption_size)\n",
      "100%|████████████████████████████████████████| 100/100 [01:33<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "positives_filter = family_subset\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model, \n",
    "                             filter_triples=positives_filter,   # Corruption strategy filter defined above \n",
    "                             use_default_protocol=True, # corrupt subj and obj separately while evaluating\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.95\n",
      "Hits@10: 0.99\n",
      "Hits@3: 0.98\n",
      "Hits@1: 0.92\n"
     ]
    }
   ],
   "source": [
    "mrr = mrr_score(ranks)\n",
    "print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "hits_10 = hits_at_n_score(ranks, n=10)\n",
    "print(\"Hits@10: %.2f\" % (hits_10))\n",
    "hits_3 = hits_at_n_score(ranks, n=3)\n",
    "print(\"Hits@3: %.2f\" % (hits_3))\n",
    "hits_1 = hits_at_n_score(ranks, n=1)\n",
    "print(\"Hits@1: %.2f\" % (hits_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new triples\n",
    "\n",
    "This is where the error is enountered :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - DeprecationWarning: use_default_protocol will be removed in future. Please use corrupt_side argument instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\johan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ampligraph\\latent_features\\models\\EmbeddingModel.py:1329: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if corruption_entities == 'all':\n",
      " 17%|██████▌                                | 421/2500 [00:43<03:32,  9.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-087fc6795566>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdiscoveries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscovery_ranks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscover_facts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfamily_subset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_candidates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentities_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentities_subset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ampligraph\\discovery\\discovery.py\u001b[0m in \u001b[0;36mdiscover_facts\u001b[1;34m(X, model, top_n, strategy, max_candidates, target_rel, entities_subset, seed)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;31m# Get ranks of candidate statements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         ranks = evaluate_performance(candidates, model=model, filter_triples=X, use_default_protocol=True, entities_subset=entities_subset,\n\u001b[1;32m--> 182\u001b[1;33m                                      verbose=False)\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;31m# Select candidate statements within the top_n predicted ranks standard protocol evaluates against\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ampligraph\\evaluation\\protocol.py\u001b[0m in \u001b[0;36mevaluate_performance\u001b[1;34m(X, model, filter_triples, verbose, filter_unseen, entities_subset, corrupt_side, ranking_strategy, use_default_protocol)\u001b[0m\n\u001b[0;32m    917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdataset_handle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m             \u001b[0mdataset_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 919\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ampligraph\\evaluation\\protocol.py\u001b[0m in \u001b[0;36mevaluate_performance\u001b[1;34m(X, model, filter_triples, verbose, filter_unseen, entities_subset, corrupt_side, ranking_strategy, use_default_protocol)\u001b[0m\n\u001b[0;32m    905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Making predictions.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 907\u001b[1;33m         \u001b[0mranks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ranks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_handle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Ending Evaluation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ampligraph\\latent_features\\models\\EmbeddingModel.py\u001b[0m in \u001b[0;36mget_ranks\u001b[1;34m(self, dataset_handle)\u001b[0m\n\u001b[0;32m   1683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1684\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_dataset_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1685\u001b[1;33m                 \u001b[0mrank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1686\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'corrupt_side'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT_CORRUPT_SIDE_EVAL\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m's,o'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m                     \u001b[0mranks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "discoveries, discovery_ranks = discover_facts(family_subset, model, top_n = 500, max_candidates = 2500, entities_subset = entities_subset, seed = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([['Q828550', 'child', 'Q2426845']], dtype=object)\n",
    "b = np.array([['Q1774982', 'father', 'Q215546']], dtype=object)\n",
    "c = np.array([['Q6845092', 'mother', 'Q16840232']], dtype=object)\n",
    "d = np.array([['Q5649896', 'relative', 'Q2426845']], dtype=object)\n",
    "e = np.array([['Q65428', 'sibling', 'Q110374'],['Q380341', 'sibling', 'Q313219'],['Q24082781', 'sibling', 'Q5543457']], dtype=object)\n",
    "f = np.array([], dtype=object)\n",
    "g = np.array([], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = [a,b,c,d,e,f,g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = [a.tolist(),b.tolist(),c.tolist(),d.tolist(),e.tolist(),f.tolist(),g.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in disc for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Q828550', 'child', 'Q2426845'],\n",
       " ['Q1774982', 'father', 'Q215546'],\n",
       " ['Q6845092', 'mother', 'Q16840232'],\n",
       " ['Q5649896', 'relative', 'Q2426845'],\n",
       " ['Q65428', 'sibling', 'Q110374'],\n",
       " ['Q380341', 'sibling', 'Q313219'],\n",
       " ['Q24082781', 'sibling', 'Q5543457']]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Q1000366', 'child', 'Q1701445'],\n",
       "       ['Q1000366', 'child', 'Q6776382'],\n",
       "       ['Q1000505', 'spouse', 'Q268177'],\n",
       "       ...,\n",
       "       ['Q913574', 'spouse', 'Q235629'],\n",
       "       ['Q953878', 'relative', 'Q314514'],\n",
       "       ['Q9749', 'sibling', 'Q706559']], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258341, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
