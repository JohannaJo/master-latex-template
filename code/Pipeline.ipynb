{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - All triples will be processed in the same batch (batches_count=1). When processing large graphs it is recommended to batch the input knowledge graph instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import config\n",
    "import models # load pretrained_models\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from rule_mining import rule_mining\n",
    "from kb_extension import extend_kb\n",
    "from rule_comparison import plot_pie_chart, get_common_rules, display_comparison\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule mining comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258235, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original knowlege base\n",
    "original_kb = np.loadtxt(\"family_subset.txt\", dtype = 'object')\n",
    "original_kb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine rules from original knowledge base\n",
    "original_rules = rule_mining(original_kb)\n",
    "\n",
    "# convert metrics to correct datatype\n",
    "original_rules['PCA Confidence'] = original_rules['PCA Confidence'].apply(lambda x: float(x.replace(',','.')))\n",
    "original_rules['Head Coverage'] = original_rules['Head Coverage'].apply(lambda x: float(x.replace(',','.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_rules_median_PCA = original_rules[\"PCA Confidence\"].median()\n",
    "original_rules_median_HC = original_rules[\"Head Coverage\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save rules mined from original kb\n",
    "original_rules.to_pickle(\"./original_rules.pkl\")\n",
    "\n",
    "# load saved rules\n",
    "# original_rules = pd.read_pickle(\"./original_rules.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "#original_kb = np.loadtxt(\"/testing/family_subset_test.txt\", dtype = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "loaded_models = [models.complEx, models.distMult, models.transE, models.randomBaseline]\n",
    "entity_selection_methods = [\"probabilistic\"]#, \"random\", \"most_frequent\", \"least_frequent\"]\n",
    "candidate_admittance_criteria = config.rank_cutoffs# + config.percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_combinations= []\n",
    "for model in loaded_models:\n",
    "    for method in entity_selection_methods:\n",
    "        for criteria in candidate_admittance_criteria:\n",
    "            model_name = model.name\n",
    "            parameter_combinations.append([model_name, method, criteria])\n",
    "parameter_combinations = pd.DataFrame(parameter_combinations, columns=[\"Model\", \"Entity_selection\", \"Candidate_criteria\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_combinations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameter combinations to file\n",
    "with open(\"parameter_combinations.pkl\", \"wb\") as file:\n",
    "    pickle.dump(parameter_combinations, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Home/siv30/fak006/miniconda/envs/ampligraph/lib/python3.7/site-packages/ampligraph/latent_features/models/EmbeddingModel.py:1329: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if corruption_entities == 'all':\n",
      "100%|██████████| 600/600 [00:00<00:00, 1567.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Extension    Model Entity_selection Candidate_criteria\n",
      "0         39  ComplEx    probabilistic   (rank_cutoff, 1)\n",
      "  Extension    Model Entity_selection Candidate_criteria\n",
      "0        39  ComplEx    probabilistic   (rank_cutoff, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Home/siv30/fak006/miniconda/envs/ampligraph/lib/python3.7/site-packages/ampligraph/latent_features/models/EmbeddingModel.py:1329: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if corruption_entities == 'all':\n",
      "100%|██████████| 600/600 [00:00<00:00, 1681.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Extension     Model Entity_selection Candidate_criteria\n",
      "0         33  DistMult    probabilistic   (rank_cutoff, 1)\n",
      "  Extension     Model Entity_selection Candidate_criteria\n",
      "0        39   ComplEx    probabilistic   (rank_cutoff, 1)\n",
      "0        33  DistMult    probabilistic   (rank_cutoff, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Home/siv30/fak006/miniconda/envs/ampligraph/lib/python3.7/site-packages/ampligraph/latent_features/models/EmbeddingModel.py:1329: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if corruption_entities == 'all':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Extension   Model Entity_selection Candidate_criteria\n",
      "0         49  TransE    probabilistic   (rank_cutoff, 1)\n",
      "  Extension     Model Entity_selection Candidate_criteria\n",
      "0        39   ComplEx    probabilistic   (rank_cutoff, 1)\n",
      "0        33  DistMult    probabilistic   (rank_cutoff, 1)\n",
      "0        49    TransE    probabilistic   (rank_cutoff, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Home/siv30/fak006/miniconda/envs/ampligraph/lib/python3.7/site-packages/ampligraph/latent_features/models/EmbeddingModel.py:1329: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if corruption_entities == 'all':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Extension           Model Entity_selection Candidate_criteria\n",
      "0         29  RandomBaseline    probabilistic   (rank_cutoff, 1)\n",
      "  Extension           Model Entity_selection Candidate_criteria\n",
      "0        39         ComplEx    probabilistic   (rank_cutoff, 1)\n",
      "0        33        DistMult    probabilistic   (rank_cutoff, 1)\n",
      "0        49          TransE    probabilistic   (rank_cutoff, 1)\n",
      "0        29  RandomBaseline    probabilistic   (rank_cutoff, 1)\n"
     ]
    }
   ],
   "source": [
    "mined_rules = []\n",
    "kb_extensions = []\n",
    "extension_sizes = pd.DataFrame([], columns=[\"Extension\", \"Model\", \"Entity_selection\", \"Candidate_criteria\"])\n",
    "for model in loaded_models:\n",
    "    for method in entity_selection_methods:\n",
    "        for criteria in candidate_admittance_criteria:\n",
    "            extended_kb, admitted_candidates = extend_kb(original_kb, model, method, criteria, max_entities=config.max_entities)\n",
    "            admitted_w_parameters = pd.DataFrame([[len(admitted_candidates), model.name, method, criteria]], columns=[\"Extension\", \"Model\", \"Entity_selection\", \"Candidate_criteria\"])\n",
    "            extension_sizes = extension_sizes.append(admitted_w_parameters)\n",
    "            rules = rule_mining(extended_kb)\n",
    "            kb_extensions.append(admitted_candidates)\n",
    "            mined_rules.append(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extension</th>\n",
       "      <th>Model</th>\n",
       "      <th>Entity_selection</th>\n",
       "      <th>Candidate_criteria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>ComplEx</td>\n",
       "      <td>probabilistic</td>\n",
       "      <td>(rank_cutoff, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>DistMult</td>\n",
       "      <td>probabilistic</td>\n",
       "      <td>(rank_cutoff, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>TransE</td>\n",
       "      <td>probabilistic</td>\n",
       "      <td>(rank_cutoff, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>RandomBaseline</td>\n",
       "      <td>probabilistic</td>\n",
       "      <td>(rank_cutoff, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Extension           Model Entity_selection Candidate_criteria\n",
       "0        39         ComplEx    probabilistic   (rank_cutoff, 1)\n",
       "0        33        DistMult    probabilistic   (rank_cutoff, 1)\n",
       "0        49          TransE    probabilistic   (rank_cutoff, 1)\n",
       "0        29  RandomBaseline    probabilistic   (rank_cutoff, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extension_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert metrics to correct datatype\n",
    "for rule_set in mined_rules:\n",
    "    rule_set['PCA Confidence'] = rule_set['PCA Confidence'].apply(lambda x: float(x.replace(',','.')))\n",
    "    rule_set['Head Coverage'] = rule_set['Head Coverage'].apply(lambda x: float(x.replace(',','.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mined_rules[0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mined rules to file\n",
    "with open(\"mined_rules.pkl\", \"wb\") as file:\n",
    "    pickle.dump(mined_rules, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mined rules to file\n",
    "with open(\"kb_extensions.pkl\", \"wb\") as file:\n",
    "    pickle.dump(kb_extensions, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mined_rules = pd.read_pickle(\"./mined_rules.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine to single dataframe\n",
    "Combine the list of rule set dataframes to a single large dataframe. Add columns for parameter values used to mine rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe that adds information about the parameters used to each row containing a rule\n",
    "if len(mined_rules) != len(parameter_combinations):\n",
    "    print(\"ERROR: number of given parameter combinaitons, \" + len(parameter_combinations) + \" is not equal to those actually used: \" + len(mined_rules))\n",
    "for i, parameter_row in parameter_combinations.iterrows():\n",
    "    number_of_rules = len(mined_rules[i])\n",
    "    parameter_list = parameter_row.values.tolist()\n",
    "    parameter_full = [copy.deepcopy(parameter_list) for j in range(number_of_rules)]\n",
    "    parameter_full_df = pd.DataFrame(parameter_full, columns=[\"Model\", \"Entity_selection\", \"Candidate_criteria\"])\n",
    "    mined_rules[i] = pd.concat([mined_rules[i], parameter_full_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add original rules to dataframe\n",
    "number_of_rules = len(original_rules)\n",
    "parameter_list = [\"Original rules\",\"Original rules\",\"Original rules\"]\n",
    "parameter_full = [parameter_list for j in range(number_of_rules)]\n",
    "parameter_full_df = pd.DataFrame(parameter_full, columns=[\"Model\", \"Entity_selection\", \"Candidate_criteria\"])\n",
    "original_rules_parameters= pd.concat([original_rules, parameter_full_df], axis=1)\n",
    "mined_rules.append(original_rules_parameters)\n",
    "mined_rules_parameters = pd.concat(mined_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add rules mined from randomly selected candidates\n",
    "extended_kb, admitted_candidates = extend_kb(original_kb, models.complEx, \"probabilistic\", (\"random\", 0), max_entities=config.max_entities)\n",
    "rules = rule_mining(extended_kb)\n",
    "number_of_rules = len(rules)\n",
    "parameter_list = [\"Rand cand\",\"Rand cand\",\"Rand cand\"]\n",
    "parameter_full = [parameter_list for j in range(number_of_rules)]\n",
    "parameter_full_df = pd.DataFrame(parameter_full, columns=[\"Model\", \"Entity_selection\", \"Candidate_criteria\"])\n",
    "original_rules_parameters= pd.concat([rules, parameter_full_df], axis=1)\n",
    "original_rules_parameters['PCA Confidence'] = original_rules_parameters['PCA Confidence'].apply(lambda x: float(x.replace(',','.')))\n",
    "original_rules_parameters['Head Coverage'] = original_rules_parameters['Head Coverage'].apply(lambda x: float(x.replace(',','.')))\n",
    "mined_rules.append(original_rules_parameters)\n",
    "mined_rules_parameters = pd.concat(mined_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine rule sets into one large dataframe\n",
    "mined_rules_parameters = pd.concat(mined_rules)\n",
    "\n",
    "# change datatype to string\n",
    "mined_rules_parameters['Candidate_criteria'] =  mined_rules_parameters.Candidate_criteria.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to file\n",
    "with open(\"mined_rules_parameters.pkl\", \"wb\") as file:\n",
    "    pickle.dump(mined_rules_parameters, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_kb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in kb_extensions:\n",
    "    print(len(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mined_rules_parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7d03622a3391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmined_rules_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mined_rules_parameters' is not defined"
     ]
    }
   ],
   "source": [
    "mined_rules_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
