\chapter{Background}

This chapter presents knowledge graphs and different paradigms for how to interpret information missing from a KG. Then we continue with knowledge graph embeddings where we examine the training and evaluation process and explain the ideas behind the three knowledge graph embedding architectures used in the experiments. Finally, the chapter introduces rule mining by first giving a general overview of rule-based machine learning before focusing on the \textit{association rule mining} approach.

\section{Knowledge Graphs}
There is no single agreed upon definition of \glspl{kg} \cite{bergman_2019, bonatti2019knowledge, ehrlinger2016towards}. Definitions and usages vary from specific technical proposals to more general descriptions. In this thesis we will use the more inclusive definition similar to the one proposed by Hogan et al. \cite{hogan2020knowledge}, where we view a \gls{kg} as \textit{a graph of data intended to capture the semantic connections within real world knowledge, where nodes represent relevant entities and edges represent relations between these entities}. The type of graph may vary, i.e. it may be simple, directed, etc. A graph may contain knowledge over a broad range of domains, such as Wikidata \cite{lehmann2015dbpedia}, or be limited to a specific domain, such as DBpedia \cite{fellbaum2010wordnet}. The concept of ``knowledge'' has been widely debated in epistemology, but here we will use it to mean descriptive knowledge, meaning facts that can be stated. Knowledge can be simple statements, such as ``\textit{Leo is a cat}'', or quantified statements such as ``\textit{at least one cat is black}''. KGs are not expressive enough for quantified statements, where ontologies or rules would be more appropriate. Additional knowledge can be inferred from KGs through inductive or deductive methods. For example from a KG containing the information that ``\textit{Leo is a cat}'' and ``\textit{cats are mammals}'', one can deductively infer that ``\textit{Leo is a mammal}''. If all cats mentioned in the knowledge graph like to eat fish, then one can inductively infer ``\textit{cats like to eat fish}''.

\begin{figure}[h]
\centering
\begin{tikzpicture}
    \node[shape=circle,draw=black] (L) at (0,0) {Leo};
    \node[shape=circle,draw=black] (C) at (3,0) {Cat};
    \node[shape=circle,draw=black] (M) at (1.5,3) {Mammal};

   % \path [->] (L) edge node[left] {$IsA$} (C);
   \draw [->] (L) -- (C);
   \draw [decoration={text along path,
    text={is a},text align={center}},decorate]  (L) -- (C);
    
    \draw [->] (C) -- (M);
   \draw [decoration={text along path,
    text={subclass},text align={center}},decorate]  (M) -- (C);
    
    \draw [dotted, ->] (L) -- (M);
   \draw [decoration={text along path,
    text={is a},text align={center}},decorate]  (L) -- (M);
    
\end{tikzpicture}

\caption{Example of a knowledge graph, where the dotted line represents a relationship that can be deductively inferred.} \label{fig:KGexample}
\end{figure}

In this thesis we will loosely follow the Resource Description Framework (RDF) standard and view KGs as sets of semantic triples. RDF is a standard for representation and exchange of graph data introduced by \gls{w3c}. Semantic triples are the data types used in the RDF data model. A triple, as the name suggests, is a tuple of three elements. It has the form ( subject, predicate, object) and can therefore represent statements about semantic data, for example ``\textit{Cats are mammals}", or ``\textit{Ann knows Bob}". These RDF statements express relationships between two resources, these resources being the subject and the object, while the predicate encapsulates the nature of the relationship. The relationship is phrased in a directional way, and so a set of RDF statements can also be viewed as a directed graph. The graph represents these triple statements, where the predicate in the triple denotes the edge going from the subject to the object, both of which are vertices.

\begin{lstlisting}[caption={Example of RDF triple set written in informal pseudocode.},label={RDF_triples_example}][h]
<Leo> <is a> <cat>
<cat> <is a> <mammal>
<Ann> <knows> <Bob>
<Ann> <is a> <person>
<Bob> <is a> <person>
<Ann> <has pet> <Leo>
\end{lstlisting}

\begin{figure}[h]
\centering
\begin{tikzpicture}
    \node[shape=circle,draw=black] (L) at (3.9,0) {Leo};
    \node[shape=circle,draw=black] (P) at (0,2.5) {Person};
    \node[shape=circle,draw=black] (A) at (1,0) {Ann};
    \node[shape=circle,draw=black] (B) at (2.5,2.5) {Bob};
    \node[shape=circle,draw=black] (C) at (6,0) {Cat};
    \node[shape=circle,draw=black] (M) at (5,2.5) {Mammal};

   % \path [->] (L) edge node[left] {$IsA$} (C);
   \draw [->] (L) -- (C);
   \draw [decoration={text along path,
    text={is a},text align={center}},decorate]  (L) -- (C);
    
    \draw [->] (L) -- (M);
   \draw [decoration={text along path,
    text={is a},text align={center}},decorate]  (L) -- (M);
    
    \draw [->] (A) -- (B);
   \draw [decoration={text along path,
    text={knows},text align={center}},decorate]  (A) -- (B);
    
    \draw [->] (A) -- (L);
   \draw [decoration={text along path,
    text={has pet},text align={center}},decorate]  (A) -- (L);
    
    \draw [->] (A) -- (P);
   \draw [decoration={text along path,
    text={is a},text align={center}, reverse path},decorate]  (A) -- (P);
    
    \draw [->] (B) -- (P);
   \draw [decoration={text along path,
    text={is a},text align={center}, reverse path},decorate]  (B) -- (P);
    
\end{tikzpicture}

\caption{Informal visualization of the KG consisting of the example triples from Listing \ref{RDF_triples_example}} \label{fig:KGexample}
\end{figure}

With this type of data organisation one can for example query for a list of all people who own cats in the dataset.

\subsection{Integrity of KGs}
\label{Integrity_of_KGs}
Generally, KGs contain only true facts. As with all databases, there seldom is a use in documenting all things that are not true. By the \textit{closed world assumption } (CWA) all facts not present in the KG are considered false. For example, by the KG in figure \ref{fig:KGexample} the statement \texttt{<Ann> <has sibling> <Bob>} is false under the CWA, as it is not present in the KG. So under the CWA Bob is not a sibling of Ann. The \textit{open world assumption} (OWA) makes no such claims and  the validity of a triple not present in the KG is considered unknown. In the above example Bob is therefore neither considered a sibling of Ann nor not a sibling of Ann under the OWA.

In the context of KGs the OWA is often more justified, as most large interesting KGs are far from complete. For example, the KG Wikidata5M does not contain information about the national bird of countries. This of course does not make the statement ``\textit{The kiwi is the national bird of New Zealand}" any less true. The information has simply not been included in the KG. Another example is Freebase, the precursor to Wikidata, in which 70\% of people listed had the place-of-birth attribute missing \cite{west2014knowledge}.

\begin{figure}[htp]
    \centering
    \includegraphics[width=10cm]{figures/kb_venn.png}
    \caption{KB prediction under incompleteness}
    \label{KB_predictions}
\end{figure}

The OWA has a central problem regarding machine learning; it fails to provide counterexamples. Because missing facts are assumed to be neither true nor false, there are no false facts to give as examples when mining rules or training an embedding model. In the context of the predictions, marked with red in \cref{KB_predictions}, we want to maximize B over D. Under the OWA, however, there are no false facts, so we don't know what B and D are. The authors of AMIE therefore introduced a new paradigm called the \textit{partial completeness assumption} (PCA) \cite{amie}. It assumes that if $r(x, y) \in KB true$ for some entities $x$, $y$, then
\[\forall y' : r(x, y') \in KBtrue \cup NEWtrue \Rightarrow r(x, y') \in KBtrue\]
, where $x$ is the \textit{head} of the triple (the first variable in the binary predicate) and $y$ is the \textit{tail} of the rule (the second varaible in the binary predicate).
This assumption says that if the KG already has $r$-related information about the entity $x$,  then it contains \textit{all} $r$-related information about $x$. For example if a KG only contains \texttt{<Ann> <has sibling> <Bob>} and no other sibling entries with Ann as the head, then by the PCA Bob is Ann's only sibling. All other facts claiming that Ann has other siblings will therefore be negative examples. If we then however ask what \textit{friends} Ann has in a knowledge base without information about Ann's friends, then one cannot conclude that Ann is friendless. PCA is a more particular version of the broad \textit{partial-closed world assumption} (PCWA), where the KG generally is treated under the OWA, but parts of it that are considered complete are treated under the CWA \cite{motro1989integrity}. The PCA is particular in the sense that it specifically defines what parts of the KG should be treated under closed-world semantics.



\section{Knowledge Graph Embeddings}
Let $\mathcal{K}$ be a KG with triples of the form $<h, r, t>$ with $r\in \mathbb{R}$ and $h, t \in \mathbb{E}$, where $\mathbb{R}$ and $\mathbb{E}$ are respectively the set of all relations and entities in $\mathcal{K}$. To simplify the explanation we let the dimension of both entities and relations in the embedding space to be $d$.
Given $\mathcal{K}$ and $d$, a KG embedding seeks to represent all entities and relations in the continuous vector space of $d$ dimensions. These representations are meant to capture the semantic information in the graph. An embedding that manages this can then be used to evaluate the probability of new facts and identify false information in $\mathcal{K}$, two tasks respectively called \textit{link prediction} and \textit{triple classification}.

\begin{figure}[htp]
    \centering
    \includesvg[inkscapelatex=false,width=1\textwidth,keepaspectratio]{figures/KG_embeddings/KG_embedding_diag.svg}
    \caption{KG embedding process. Them embedding of a KG can be used for machine learning tasks.}
    \label{KG_embdding_diag}
\end{figure}

The procedure for training KG embedding models is similar to any other statistical-based machine learning. The values of the embeddings are usually initialized as random values. These embeddings are continuously optimized through a training loop, which stops once the stop condition is met (usually overfitting on the training set). For each triple in the training set, $\eta$ negative counterexamples are generated by triple corruption. This is done by swapping out either the head $h$ or tail $t$ (not both) with some other $h', t' \in \mathbb{E}$ \cite{TransE}. Both the original triple and the corrupted triples are added to the training batch. A \textit{scoring function} is used to measure the ``goodness" or plausibility of a triple. The model should give a good score to triples from the KG, and a bad score to the corrupted triples. By updating the embedding to optimize the scoring function the model should at the end of training have meaningful embeddings that can accurately evaluate unseen triples. In the training process this is done by minimizing the model's \textit{loss function}.

\subsection{Loss functions}
A loss function is a function that assigns a ``cost" to an event in the form of a real number. The loss function is minimized with some optimization algorithm, such as stochastic gradient descent. In the context of KG embedding models the loss function is used to update the embeddings \cite{dai2020survey}. There are many different types of loss functions, such as ranking losses \cite{TransE}, binary logistic regression \cite{complEx} and multiclass log loss \cite{kadlec2017knowledge}. We will briefly present the versions of ranking loss and multiclass log loss that were used in our experiments.

\subsubsection{Pairwise, margin-based ranking loss}
\textit{Learning to rank} is a machine learning task where a model is trained to rank a set of data points. In the \textit{pairwise} approach the problem is approximated to a binary classification problem, so the task becomes to determine which data point out of a pair is the better datapoint. The classifier takes as input two datapoints, one of higher rank $x_{+}$ and one of lower rank $x_{-}$, and has as goal to minimize the loss function which penalizes cases where $x_{-}$ is given a higher rank. So the goal is to create ``distance" between positive and negative datapoints in the model's inner representation of the training data. In margin-based ranking loss a minimum value is set for this distance, so that once that distance is achieved the model no longer needs to make updates regarding the pair of datapoints with adequate distance, thereby allowing training to be spent on learning other more harder differences.  The authors of TransE use this pairwise, margin-based ranking approach as their loss function \cite{TransE}. Given a set of training triples $\mathcal{S}$, a scoring function $f$ and a margin $\gamma > 0$, the pairwise, margin-based ranking loss is defined as:

\[\mathcal{L}=\sum_{(h, r, t) \in \mathcal{S}}\sum_{(h', r, t') \in \mathcal{S'}}[\gamma + f(h, r, t) - f(h', r, t')]\]

where $\mathcal{S'}$ is the set of corrupted triples. This loss function favours lower scores for corrupted triples and a higher scores for non-corrupted triples. The aim is not to give a negative triples a score below a certain value nor positive triples a score above a certain value, rather the goal is to create distance between them. This loss function can be used across many KG embedding models, as it is the \textit{scoring function} that differs across models. The scoring functions for TransE, DistMult and ComplEx will be presented in Section \ref{KG_embeddings_section}.


\subsubsection{Negative log-likelihood loss}
This loss function was used in the paper introducing ComplEx \cite{complEx}. Simply put, the function uses likelihood minimization to push the model toward the embedding that minimises the likelihood of loss. It is the \textit{opposite} of maximum likelihood estimation, where one wants to maximise the likelihood of some data points given a set of parameters, hence the name \textit{negative} log-likelihood.
Since the likelihood of facts in a KG are independent, the likelihood of a set of triples is the same as the product of the likelihoods of each individual triple. With many of data points, multiplying many small probabilities with each other quickly leads to unmanageable small numbers. This causes \textit{underflow}, where a number is too small for a computer to be capable of storing it. To solve this problem, we take the log of the likelihoods so that products become sums. As log functions monotonically increase, the relative likelihood is maintained. For example if $f(h,r,t) \geq f(h', r, t')$ then $log(f(h,r,t)) \geq log(f(h', r, t'))$, so the $\geq$ is maintained. Since the goal is to create distance between positive and negative triples, only the relative difference between them needs to be maintained. Thus the negative log-likelihood loss is:

\[\mathcal{L}=\sum_{(h, r, t) \in \mathcal{S} \cup \mathcal{S'}}log(1+exp(-y \, f(h, r, t)))\]

where $y\in [1, -1]$ is the label of the triple (positive or negative).


%This goes pretty in depth: %https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9416312

    
\subsection{Performance indicators}
\label{Performance_indicators}
Three different performance indexes are commonly used to evaluate the embedding quality of a model. While KG embedding models assign scores to triples, these scores are relative and cannot be used to give an absolute estimate of how well a model evaluates a triple. Instead, the scores are compared with those assigned to other triples so that the \textit{rank} of a triple can be used as an approximation of absolute measurement. Note being ranked first (rank number 1) is best, and so when a fact is described as having a ``high rank" then the rank number itself is low. Similarly, if a triple has a low rank, the rank number assigned to it is high.

As the performance indicators are simple to calculate, they are suitable for measuring performance on a large scale. With $\mathcal{T}$ as the set of ranked triples and $\mathcal{S}$ as the set of true triples, we can define three performance indexes.

\subsubsection{Hits@K}
\label{Hits@k}
Hits@K is the probability of finding the correct triple in the top K ranked triples. Usually $k=10$ or lower. This metric measures the model's ability to rank positive triples higher than corrupted ones.
\[\text{Hits@K}=\frac{|\{t\in \mathcal{T} : t_{rank}<k, t \in \mathcal{S}\}|}{|\mathcal{T}|}\]
The larger the value, the better the performance of the model.

\subsubsection{Mean rank}
Mean rank (MR) is the average rank of all the ranks assigned to the triples in the test set. A smaller value indicates a better model, because that means that more triples from the knowledge graph have been given higher ranks and accordingly their rank numbers are smaller.
\[MR=\frac{1}{|\mathcal{T}|}\sum_{t\in\mathcal{T}}t_{rank}\]
MR has an advantage over Hits@K in being more sensitive to slight changes in the  model, because if the changes do not affect the top $k$ ranked triples then the Hits@K score remains unchanged.

\subsubsection{Mean reciprocal rank}
Mean reciprocal rank (MRR) is a measurement for the number of triples correctly ranked. If the triple with the best rank is a positive triple, then 1 is added. If the triple with the second best rank is positive, then $\frac{1}{2}$ is added, etc. If a ranked triple is negative nothing is deducted, the fraction simply isn't added to the MRR.
\[MRR=\frac{1}{|\mathcal{T}|}\sum_{t\in\mathcal{T}}t_{rank} : t\in \mathcal{S}\]
The larger the value, the better the model.
    
\subsection{KG embedding model architectures}
\label{KG_embeddings_section}
KG embedding models differ mainly in three aspects: (1) how entities and relations are represented, (2) the scoring function, and (3) how the embedding is optimized. The difficulty with embedding KGs is that there are many different entities and relationships, so the embedding model needs to be generic enough to capture all the different entities and relationships at the same time. We now consider the three models used in this thesis.

\subsubsection{TransE}
\label{TransE_peaked_in_2013}
In 2013 Mikolov et al. proposed a technique for natural language processing called \textit{word2vec} \cite{mikolov2013distributed,mikolov2013efficient}, which used a word-embedding algorithm that managed to capture some the of semantics in words. Words were represented as vectors, and the authors found that the embeddings had interesting qualities, such as
\[\overrightarrow{King} - \overrightarrow{Queen} \approx \overrightarrow{Man} -\overrightarrow{Woman}\]
where the words with an overhead arrow denote \textit{word2vec}'s vector embedding of the word. Inspired by this, Bordes et al. applied this idea to embedding entities and relations in KGs, and proposed the embedding model TransE \cite{TransE}. A main motivation behind this approach was that ``\textit{hierarchical relationships are extremely common in KBs and translations are the natural transformations for representing them.}" \cite{TransE}. This approach learns entity embeddings and treats relations as translations in the entity embedding space.  For a true triple this means that the tail entity should be very close to the head entity plus the relation translation in the embedding space. 

\begin{figure}[htp]
    \centering
    \includesvg[inkscapelatex=false,width=0.4\textwidth,keepaspectratio]{figures/KG_embeddings/IKEA_TransE.svg}
    \caption{Visualization of entity and relation embedding for TransE.}
    \label{IKEA_TransE}
\end{figure}

If $\text{\textbf{(h, r, t)}}$ denote an embedding of a head, relation and tail, then $\textbf{h} + \textbf{r} \approx \textbf{t}$. The score function $f_{TransE}$ is thus defined as the distance between $\textbf{h} + \textbf{r}$ and $\textbf{t}$, using $l_1$ or $l_2$ to calculate distance:
\[f_{TransE}(h, r, t) = ||\textbf{h} + \textbf{r} - \textbf{t}||_{l_1/l_2}\]

Let $d$ denote the dimension of the embedding space. Per entity one vector $\textbf{e}\in \mathbb{R}^d$ needs to be learned and per relationship one translation vector $\textbf{d}_r\in \mathbb{R}^d$ needs to be learned. Let $n_e$ and $n_r$ be the number of unique entities and relations respectively. The number of parameters needed to be learned for TransE is thus $\mathcal{O}(n_e d + n_r d)$.


TransE does have some limitations. For example, it is not capable of properly embedding complex relations, meaning 1-N, N-1, or N-N relations. Imagine a complex relation such that $\forall i \in \{1,2, ..., n\}$, $(h, r, t_i )\in \mathcal{S}$, where $\mathcal{S}$ is the set of correct triples. Following the TransE approach, $\textbf{h}+\textbf{r}\approx \textbf{t}_i$, therefore $\textbf{t}_1 \approx \textbf{t}_2 \approx ... \approx \textbf{t}_i$, even though the tail entities are not semantically similar. Taking an example from figure \ref{IKEA_TransE}, the store IKEA sells both furniture and food, causing TransE to perhaps give the semantically dissimilar concepts a similar entity embedding. Other translation-based models, such as TransH \cite{transH}, TranR \cite{transR} and TransD \cite{transD}, have later been proposed to alleviate some of the limitations of TransE.

\subsubsection{DistMult}
DistMult is a tensor factorization-based model. In such models triples in a KG are transformed into a 3D binary tensor $\mathcal{X}$. We want the embeddings of the entities and relations to be such that one can mathematically combine them to obtain the tensor representing the KG. As seen in \cref{tensor_model_fig}, in the KG tensor each relation is represented by an $n \times n$, where $n$ is the number of unique entities. The number of relations is denoted by $m$, so $\mathcal{X}\in \mathbb{R}^{n \times n \times m}$. An element $X_{ijk} = 1$ if there is a relation of type $(i, j, k)$ in the graph, and $X_{ijk} = 0$ otherwise.

\begin{figure}[htp]
    \centering
    \includesvg[inkscapelatex=false,width=0.4\textwidth,keepaspectratio]{figures/KG_embeddings/DistMult_matrices.svg}
    \caption{A tensor model of a knowledge graph \cite{dai2020survey}.}
    \label{tensor_model_fig}
\end{figure}

The tensor factorization-based model RESCAL \cite{RESCAL} uses rank-$d$ factorization to obtain the latent semantics. The main idea of this method is that
\begin{center}
 $\mathcal{X}_k \approx AR_k A^T$, for $k = 1,2,...,m$
\end{center}
where $\mathcal{X}_k$ is the $k$th slice in the KG tensor, $A\in \mathbb{R}^{n\times d}$ is the matrix representing all entities and $R_k\in \mathbb{R}^{d\times d}$ is a matrix representing the $k$th relation.
So the scoring function used in RESCAL is
\[f_ {\text{RESCAL}}(h, r, t) =\textbf{h}^{\top}\textbf{M}_r\textbf{t}\]
where $\textbf{h, t}\in \mathbb{R}^{d}$ are the embedding vectors of entities and $\textbf{M}_r \in \mathbb{R}^{d\times d}$ is the semantic embedding of the relation.
This method requires thus $\mathcal{O}(n_ed + n_r d^r)$ parameters. In order to lower this complexity, DistMult restricts $\textbf{M}_r$ to be a diagonal matrix, meaning that all entries apart from those in the diagonal of the matrix are zero. After $\textbf{M}_r = \text{diag}(\textbf{r}), \textbf{r}\in\mathbb{R}^d$. The scoring function is transformed to
\[f_ {\text{DistMult}}(h, r, t) =\textbf{h}^{\top}\text{diag}(\textbf{r})\textbf{t}\]
Now only $d$ parameters need to be learned per relationship, and the number of parameters to be learned for DistMult is $\mathcal{O}(n_ed + n_r d)$. The space required is also $\mathcal{O}(n_ed + n_r d)$.

A main problem with this approach is that $f_ {\text{DistMult}}(h, r, t) = f_ {\text{DistMult}}(t, r, h)$, so DistMult cannot embed the asymmetry of a relation. This issue is adressed by later models, such as ComplEx \cite{complEx} and SimplE \cite{SimplE}.


\subsubsection{ComplEx}
ComplEx extends DistMult with complex-valued embeddings, thereby allowing it to distinguish between symmetric and asymmetric facts \cite{complEx}. This was achieved without increasing parameter or memory complexity. The imaginary and real part of the embeddings play the role of representing the ``direction" of the relation and thus asymmetric qualities can be expressed in the embedding. The scoring function for ComplEx is quite similar to that of DistMult:
\[f_ {\text{ComplEx}}(h, r, t) =\textbf{Re}(\textbf{h}^{\top}\text{diag}(\textbf{r})\overline{\textbf{t}})\]
where $\overline{\textbf{t}}$ represents the complex conjugate of \textbf{t} and \textbf{Re} means we are taking the real values of the score. With such a scoring function, triples with asymmetric relations are able to obtain different scores depending on the ordering of entities.
    

\section{Rule-based machine learning}
Rule-based machine learning has as a goal to create rules that make new true predictions going beyond the data on which the rule was applied to. In contrast, other areas of machine learning focus on training a single model that can be applied to make a broad range of predictions. Conceptually, the end result of rule-based machine learning is similar to a rule-based system.  Rule-based systems are often hand-crafted and require a knowledge expert to be curated, while rule-based machine learning requires no knowledge expert and rules are automatically created by the learning algorithm.

Classically, a rule is comprised of a condition and consequent, or a so-called "if-then" statement. \begin{center} \textbf{IF} \textit{`the condition is met'} \textbf{THEN} \textit{`the consequent holds'} \end{center}
The condition of the rule specifies attributes in the data on which the rule will be applied. If these attributes are present in this data, the condition is met. Once this happens, the attributes in the consequent should necessarily also be met. We define an \textit{atom} to be a triple in which the head and/or tail are variables. A \textit{Horn rule} is a rule where the consequent of a rule is a single atom, while the body is a set of atoms. We denote a Horn rule by $B \Rightarrow r(x, y)$ where $B$ is the body and $r(x, y)$ the head. Two examples of such rules are \ref{example_rule_1} and \ref{example_rule_2}.

\begin{equation}
hasSibling(x, y) \Rightarrow hasSibling(y,x)
\label{example_rule_1}
\end{equation}
\begin{equation}
    hasSibling(x, y), hasMother(y,z) \Rightarrow hasMother(x,z)
    \label{example_rule_2}
\end{equation}
\begin{lstlisting}[caption={Simple example knowledge base},captionpos=b, label={simple_kb_example}]
<Ann> <hasMother> <Carol>
<Ann> <hasSibling> <Bob>
<Bob> <hasSibling> <Ann>
\end{lstlisting}
Consider the two rules and knowledge base given above. Under this knowledge base the antecedent of the first rule is satisfied by both triple 2 and 3. The resulting consequent of rule \ref{example_rule_1} is also present in the knowledge base. So the reflexivity of the $hasSibling$ predicate holds in this knowledge base. The antecendent of the second rule is satisfied by triples 1 and 2 in the knowledge base, but the resulting consequent would then be $hasMother(Bob, Carol)$. Since \texttt{<BoB> <hasMother> <Carol>} is not present in the knowledge base, rule \ref{example_rule_2} does not hold. If we know that this rule is reliable, we could for example extend the incomplete knowledge base with this triple.

Within rule-based machine learning there are many different approaches, including learning classifier systems \cite{sigaud2007learning} and association rule mining \cite{agrawal1993mining}, the latter of which is the approach used in this thesis. Both aim to create a set of rules to act as a model for a set of data. The association rule mining approach will now be explained further.


\subsection{Association Rule Mining}
Association rules \cite{agrawal1993mining} are types of ``if-then" statements that describe frequent associations between items in a dataset containing \textit{transactions}. A transaction can be thought of as a set of related items. Association rule mining was originally proposed as a new method for finding relationships between sales items in stores. The idea of mining association rules over transactions has successfully been applied to many other scenarios \cite{altaf2017applications, lin2002efficient}. In the context of convenience store sales, each transaction can be thought of as a set of items that a customer has purchased. The rules are of the form $\{Sugar, Flour, Eggs\} \Rightarrow Butter$, meaning that a person who bought sugar, flour and eggs is likely to also purchase butter. The antecedent is some set of items in the dataset, while the consequent is an item often found in combination with the antecedent in the dataset.  So sugar, flour and eggs can be thought of as ``associated with" butter. These original association rules are also not Horn rules over binary predicates, but it is cited as a main inspiration for the AMIE3 algorithm used for experiments in this thesis. AMIE3 also limits rules to be in Horn form, meaning that the consequent can contain at most one predicate.

\subsection{Significance and quality measurement}
The goal is to find formal rules that make true predictions that go beyond the explicit information in the knowledge base. If we look back at \cref{KB_predictions} this means we want to maximise B and minimise D. For this we need to know what those areas are, and this is where the problem of missing negative examples from \cref{Integrity_of_KGs} occurs as the area \textbf{KB false} is empty. We consider the different measures addressing this problem.

\subsubsection{Support}
The \textit{support} of a rule is the quantity of correct predictions. If we consider \cref{KB_predictions} as a diagram representing the predictions of a rule $B \rightarrow r(x,y)$, then the support of the rule is area A. What counts as an instance of a correct prediction can vary. The authors of AMIE3 point out that if one chooses the number of instantiations of the rule, then the measure becomes non-monotonic \cite{amie3}. They give an example with the rule:
\[marriedTo(x, y) \Rightarrow marriedTo(y, x)\]
where if $hasGender(x, male)$ is added to the body, then the number of instantiations in the KG can only decrease. If on the other hand $hasFriend(x, z)$ is added to the body then the number of instantiations may increase. In order to preserve monoticity and only a single measure of support  for each rule they define support of a rule $B\Rightarrow r(x, y)$ to be the number of distinct object-subject pairs in the KB that appear in the head and tail:
\[supp(B\Rightarrow r(x, y)) :=  \# (x, y) : \exists z_1 , ...,z_m : \vec{B} \wedge r(x, y)\]


\subsubsection{Head coverage}
Support is not an absolute measurement, rather a relative measurement. It requires the complete size of the KG for the values to have meaning. This is countered with a proportional version of support called \emph{head coverage}. It is the ratio of known true facts about a relation $r$ that are implied by the rule with $r$ in its head:
\[hc(B \rightarrow r(x,y)) = \frac{support(B \rightarrow r(x,y))}{|\{(x, y) : r(x, y) \in \mathcal{K}\}|}\]
We now have an absolute measurement of significance, but this is not a measure of quality of a rule, only relevance. For this we need confidence measures.


\subsubsection{Standard Confidence} Confidence is the proportion of a rule's true predictions out of all its predictions. In order to determine if a new fact is true or false, one must make assumptions about the facts missing from the KG. The \textit{standard confidence} adopts the CWA and labels all facts not already present in the KG as false. Thus, the standard confidence of a rule is the ratio of its predictions that are in the KG:
\[conf(\vec{B}\Rightarrow r(x, y)) := \frac{supp(\vec{B}\Rightarrow r(x, y)}{\#(x, y):\exists z_1 ,..., z_m : \vec{B}}\]

If one wants to mine rules that only describe the data at hand, and has a relatively complete KG, then this is a good measure of confidence. If the aim on the other hand is to mine rules that predict new facts then standard confidence is not a good measurement as it penalizes rules that make predictions outside of the current knowledge.

\subsubsection{PCA Confidence}
Recalling the PCA from \ref{Integrity_of_KGs} we now look at AMIE's attempt at normalizing the confidence by identifying negative examples with the PCA. The confidence is not normalized by the entire set of facts, rather with the set of facts known to be true (those in the KG), and those assumed to be false (with PCA). Thus, the \textit{PCA confidence} is defined as:
\[pcaconf(\vec{B}\Rightarrow r(x, y)) := \frac{supp(\vec{B}\Rightarrow r(x, y)}{\#(x, y):\exists z_1 ,..., z_m, y' : \vec{B} \wedge r(x, y')}\]


\subsection{AMIE, AMIE+ and AMIE3}
\textcolor{red}{I treat the mining algorithm as a black box in the experiments. How much should be written about AMIE3 here? Should I write about the different versions of AMIE?}

\iffalse 
\section{Web Ontology Language}
A widely used formal language for expressing ontologies is the \gls{owl}. In OWL "Daughters are female" could be formally expressed as:

\centerline{\textsf{SubClassOf(Daughter Female)}}
Information expressed in OWL can be used to draw new conclusions. For example if we know that an individual \emph{Amy} is a daughter, then we can makes the same conclusions as earlier about Amy being female. In OWL, the fact that Amy is in the class of females can be expressed as:

\centerline{\textsf{ClassAssertion(Female amy)}}
The task of reaching such conclusions is called reasoning and the type of conclusions that can be drawn is specified by the \gls{w3c}. It specifies the \emph{semantics} of OWL, but does not present algorithms for how to derive inferences in practice. Sound and complete reasoning in OWL is of high complexity \cite{Krotzsch2012}. Therefore, when the standard was updated to OWL 2 in 2009, it introduced restricted sublanguages to address this problem. These sublanguages restrict expressivity in order to simplify the reasoning task. One of these languages is OWL 2 QL, which is based on a \gls{dl} language called DL-Lite. OWL 2 QL is intended as a language to enable easier queries to databases. The ontology language we will use is DL-Lite$_{\mathcal{R}, horn}^{\exists}$, which is a member of the DL-Lite family.



\section{Description Logics}
\gls{dls} are a family of languages used in knowledge representation and reasoning. They are generally less expressive than \gls{fol}, but more expressive than \gls{pl}. The name \textit{description logic} represents two central aspects to this language group: \emph{description}, formal expression of knowledge, and  \emph{logic}, for it's logic-based semantics. DLs are used to represent domain knowledge in a well-structured and easily interpretable way. Domain knowledge is separated into two components in DL, a \emph{terminological} part, called a TBox, and an \emph{assertional} part, called an ABox. The TBox represents knowledge about the structure of the domain, while the ABox has knowledge about specific instances. For example the fact that \emph{cats are  mammals} would be a TBox statement, while \emph{Leo is a cat} would be an ABox statement, as here we are making an assertion about the individual Leo. The combination of a TBox and an ABox is called a \emph{knowledge base} (KB).
As the semantics of DLs are logic-based it is clear when a statement is \emph{entailed} by a KB. For instance the two examples given above entail that Leo is a mammal. More importantly, this reasoning task can be automated in a DL KB. Reasoning tasks are performed with respect to the entire KB, which gives this language great power, but also comes with a computational cost. Therefore an important area of research has been to find DLs that strike a balance between expressiveness and the computational complexity of reasoning.


The two main criteria for a reasoner is that it is decidable and tractable (always correctly completed in a time that is polynomial with respect to the size of the KB). The more operators one allows in a logic the more complicated the TBox becomes, and usually the complexity for reasoning in the language increases. See \href{http://www.cs.man.ac.uk/~ezolin/dl/}{\textbf{Complexity of reasoning in Description Logics}} for an interactive look at the complexity of different DLs \cite{zolin_2013}.

\section{The Resource Description Framework}

The Resource Description Framework (RDF) is a standard for representation and exchange of graph data introduced by \gls{w3c}. Semantic triples are the data types used in the RDF data model. A triple, as the name suggests, is a tuple of three elements. It has the form ( subject, predicate, object) and can therefore represent statements about semantic data, for example "Cats are mammals", or "Ann knows Bob". These RDF statements express relationships between two resources, these resources being the subject and the object, while the predicate encapsulates the nature of the relationship. The relationship is phrased in a directional way, and so set of RDF stamements can also be viewed as a directed graph. The graph represents these triple statements, where the predicate in the triple denotes the edge going from the subject to the object, both of which are vertices.

\begin{lstlisting}[caption={Example of RDF triple set written in informal pseudocode},label={RDF_triples_example}]
<Ann> <knows> <Bob>
<Ann> <is a> <person>
<Bob> <is a> <person>
<Ann> <owns> <Leo>
<Leo> <is a> <cat>
<cat> <is a> <mammal>
<Bob> <is scared of> <Leo>
\end{lstlisting}

\begin{figure}
\centering
    \includegraphics[scale=0.3]{figures/RDF_triple}
    \caption{TODO Informal graph of the example triples from \ref{RDF_triples_example}}
    
    \label{fig:KGexample}
\end{figure}

With this type of data organisation one can for example query for a list of all people who own cats in the dataset.

\subsection{Resource Description Framework Schema}
RDF provides the abstract model for how to organize the data and sets standards for how data points relate to eachother and real-world entities. The RDF Schema (RDFS), on the other hand, is a \emph{vocabulary} in RDF that explains how nodes of a graph relate.

\section{Semantic Triples in Description Logics}
Semantic triples are 
\fi
