\chapter{Learning Horn Theories in Propositional Logic}

%\newcommand{dltext}[1]{\centerline{\textsf{#1}\newline}}
In this chapter we will look at how a neural network can represent a Horn ontology in propositional logic, and how the rules of this ontology can be learned by querying the network.

\section{Propositional Logic}
We define $V$ to be a finite set of boolean variables. A \emph{literal} over $V$ is either a variable $v \in V$ or the negation of a variable $v$, written as $\neg v$. A \emph{clause} is a disjunction ($\vee$) of literals. A \emph{formula} over $V$ is a conjunction ($\wedge$) of clauses over $V$.

A \emph{horn clause} is a clause where at most one literal is non-negated, and a \emph{Horn sentence} is a conjunction of Horn clauses. If each rule in an ontology is represented as a horn clause, then a horn sentence containing all the rules would represent the entire ontology. Rules can be viewed as if-them statements, which can be represented by implications. An implication ($\rightarrow$) can be represented as a Horn clause, where the antecedent of the implication is a conjunction of the the negated literals, and the consequent the non-negated literal.

An \emph{interpretation} $\mathcal{I}$ over $V$ assigns truth values to all variables $v$ in $V$. A variable $v$ is \emph{satisfied} by $\mathcal{I}$ if $v \in \mathcal{I}$. If a variable is not in an interpretation $\mathcal{I}$, then it is said to be \emph{falsified} by $\mathcal{I}$. If a variable $v$ is falsified by $\mathcal{I}$, then the literal $\neg v$ is satisfied by $\mathcal{I}$. For a clause $c$ to be satisfied by an interpretation $\mathcal{I}$ at least one literal in $c$ needs to be satisfied by $\mathcal{I}$. For a formula $t$ to be satisfied by an interpretation $\mathcal{I}$, each clause in the formula needs to be satisfied by $\mathcal{I}$.

If a interpretation satisfies variable, literal, clause or formula $x$, this is written as $\mathcal{I} \models x$. If an interpretation does not satisfy $x$ one writes $\mathcal{I} \not \models x $. If for every possible $\mathcal{I}$, $\mathcal{I} \models t$ implies $\mathcal{I} \models c$, then $t$ \emph{entails} $c$ ($t \models c$).


\section{Learning Framework}
We want to formally define the \empph{learning framework}. By \emph{learning} we mean the process of acquiring desired knowledge in a practical and machine-processable format. As input to the learner we give \emph{examples}, which are data points that encapsulate that knowledge. Formally, a \emph{learning framework} $F$ is defines as a pair $(E, H)$ where
\begin{itemize}
    \item $E$ is a set of all examples,
    \item $H$ is the \emph{hypothesis space}.
\end{itemize}
In this situation $H$ is the set of all formulas in propositional logic, and $E$ is the set of all interpretations over $V$. The learning framework $F$ is said to be \emph{Horn} if $H$ is restricted to the set of all Horn formulas. An example $e \in E$ is a \emph{positive example} for a hypothesis $h \in H$ iff $e \models h$, and a negative example if $e \not \models h$. The target $t$ is a fixed element in $H$ which one in the learning process wants to identify. For $t, h \in H$ a \emph{counterexample} is an example showing that $h \not \equiv t$. A \emph{positive counterexample} $e^+$ is such that $e^+ \models t$ and $e^+ \not \models h$, while for a a \emph{negative counterexample} $e^-$, $e^- \not \models t$ and $e^- \models h$.

We follow the approach proposed by Angluin \cite{DBLP:journals/ml/AngluinFP92}, and assume that the learner has access to an oracle that can answer certain types of queries about the target $t$. Here we use two types of oracles:
\begin{itemize}
    \item A \emph{Membership oracle} $MO_{E, H}$ takes as input an interpretation $\mathcal{I}$, and outputs `yes' if $\mathcal{I} \models t$ and `no' otherwise.
    \item An \emph{Equivalence oracle} $EO_{E,H}$ is a function that takes as input a hypothesis $h$ and outputs `yes' if $h \equiv t$, otherwise it outputs a counterexample for $t$ and $h$. This counterexample can be either positive or negative.
\end{itemize}
A query to $MO_{E, H}$ is called a \emph{membership query}, and a query to $EO_{E, h}$ is called an \emph{equivalence query}.

A learning framework $F_{E, H}$ is exactly learnable if there is a deterministic algorithm $A$ such that for every possible $t\in H$, it eventually halts and outputs some hypothesis $h \in H$ where $h \equiv t$. In this scenario $A$ takes as input the set of variables $V$ over which $t$ is formulated and poses membership and equivalence queries, before finally outputting a hypothesis $h \in H$ where $h \equiv t$. $F$ is \emph{exactly learnable in polynomial time} if the the number of steps required by $A$ to find an equivalent hypothesis is bounded by the size of the target and the maximum length of any counterexample encountered.

\todo[inline]{Should the definition of a \emph{safe} learning framework be included?}

\section{Neural Networks as a Representation of a Target}
In this work we will treat neural networks as a restricted version of traditional neural networks. Here, a neural network can be understood as a way of representing a target formula $t$. The input to a neural network model $N$ is a $|V|$ dimensional vector with all its values in the range $\{0, 1\}$. This input represents an interpretation $\mathcal{I}$, where 0 and 1 denote the truth values assigned to the variables in $V$. More specifically, by $\overrightarrow{\mathcal{I}}$ we denote the vector in the $|V|$ dimensional space where each entry at position $i$ is 1 if variable $v_i \in V$ is in the interpretation $\mathcal{I}$, and 0 otherwise. So $N$ is a function which takes as input an interpretation $\mathcal{I}$, represented as a vector, and outputs the satisfiability of the target formula $t$ under $\mathcal{I}$.
To train the neural network a dataset of the format $(\overrightarrow{\mathcal{I}}, l)$ is used. $l$ is either 0 or 1, indicating whether or not the interpretation $\mathcal{I}$ satisfies the target $t$. For every neural network trained on such a dataset there is a formula $t_n$ such that $N(\overrightarrow{\mathcal{I}}) = 1$ iff $\mathcal{I} \models t_N$. With a neural network $N$ as an alternative representation of a target formula $t_N$, we now look at how querying the neural network can lead us to exactly identify the target. 


\section{Extracting Horn Theories from Neural Networks}

Given a neural network $N$ that represents an unknown target formula $t_N$ in the form of a Horn sentence, we are interested in discovering this formula $t_N$. Since the formula is Horn we may employ Angluin's algorithm for learning Horn theories, called HORN \cite{DBLP:journals/ml/AngluinFP92}. Given a finite set of variables, HORN is guaranteed to exactly identify a target formulated as a Horn sentence in polynomial time. To learn the target the algorithm poses equivalence and membership queries. HORN terminates when an equivalence query returns `yes', meaning that the hypothesis and target are equivalent. Membership queries are used to update the hypothesis, which is initialized as empty and to which clauses falsified by a negative counterexample are added. HORN is guaranteed to terminate in polynomial time on the size of the target and the number of variables ($|V|$) in consideration. Using this algorithm, Horn ontologies can be extracted from a trained neural network.

In \emph{Extracting Horn Theories with Queries and Counterexamples} (citation needed) this approach of querying a neural network to extract a Horn theory was tested on a neural network trained on positive and negative examples of the target formula. I contributed to this paper by identifying the Lenses Dataset \cite{Dua:2019} that could be used to train the neural network and conducting a model selection process to produce a well-trained neural network classifier. The $MO$ was simulated with the neural network classifier, as whenever a membership query with interpretation $\mathcal{I}$ is called, the classification of $\mathcal{I}$ by the neural network is the answer to the query. The method used to simulate the EO is more of an approximation, so the equivalence between the resulting hypothesis and the target was not guaranteed. The approach did however ensure that the hypothesis constructed was \emph{probably approximately correct} (PAC) \cite{Valiant}.

Angluin also introduced an improved version of HORN, called HORN1, which has better runtime than HORN. In \emph{Extracting Horn Theories with Queries and Counterexamples} my implementation of HORN1 was used in the experiments conducted.

