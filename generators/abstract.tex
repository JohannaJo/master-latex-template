\pagenumbering{roman}
%\cite{schlichtkrull2018modeling, vashishth2019composition} (for neural networks citation)
\begin{abstract} 

\noindent Knowledge graphs (KGs) have risen in both size and use over the past few years, and there are a range of approaches for evaluating information in them. Symbolic approaches, such as rule-based machine learning, offer an explainable way to determine the appropriateness of a new fact based on rules mined from the KG in question. Some of the most successful approaches for fact prediction in KGs today are knowledge graph embeddings (KGEs) that use deep neural networks, however these lack the explainability of symbolic approaches. We would like to see how the extension of a KG using KGEs affects the rules mined from the KG. A set of rules is mined from a KG and compared with another set mined from an \textit{extended} version of said KG. The experiments examine three classical KGEs: TransE, DistMult and ComplEx, and uses the rule mining algorithm AMIE3. AMIE3 is treated as a black box during the experiment, as only the factors playing a role in the KG-extension process that are evaluated, one of which is the choice of KGE. The experiments show that there can be huge discrepancies in the rules mined based on the choice of KGE, and that TransE leads to an especially large amount of nonsensical rules being mined.

\end{abstract}

\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}
	Est suavitate gubergren referrentur an, ex mea dolor eloquentiam, novum ludus suscipit in nec. Ea mea essent prompta constituam, has ut novum prodesset vulputate. Ad noster electram pri, nec sint accusamus dissentias at. Est ad laoreet fierent invidunt, ut per assueverit conclusionemque. An electram efficiendi mea.
	
	\vspace{1cm}
	\hspace*{\fill}\texttt{Your name}\\ 
	\hspace*{\fill} 01 June, 2018
\end{abstract}
\newpage